#random.seed=1234567
run.name=tspsw
run.reset=true

# If set to "true" then substitutions present in property values will be enabled. Substitutions have the format $([key]), where [key] is the key of another property.
substitution.enable=true

###########
# evolution
###########
num.runs=1
num.generations=100000
popul.size=1024

performance.target=0.0
performance.target.type=lower
# If greater than 1 then use an average of the best performance over this many generations.
performance.target.average=10

#false means mutation probabilities are applied to all possible places a mutation could occur
#true means probabilities apply to individual as a whole; only one topological mutation can occur per individual
#note that this applies only to topological mutations, not weight mutations
topology.mutation.classic=true

#classic=[0.01, 0.5], not classic=[0.0001,] dependent on pop size. 0.03
add.neuron.mutation.rate=0.03

# Mutation rate for operator that adds neurons anywhere in the network (as 
# opposed to regular add neuron operator that only adds them in place of 
# existing connections). Only works for topology.mutation.classic=false
add.neuron.anywhere.mutation.rate=0.0

#classic=[0.01, 0.5], not classic=[0.0001,] dependent on pop size. 0.4
add.connection.mutation.rate=0.1
#[0.01, 0.3]
remove.connection.mutation.rate=0.01
#only remove weights with magnitude smaller than this
remove.connection.max.weight=1000

#should be 1.0
prune.mutation.rate=1.0

#[0.1, 0.8]
weight.mutation.rate=0.1
#[1.0, 2.0] dependent on (CPPN) weight.max/min?
weight.mutation.std.dev=1
# The amount to perturb weights by when generating the initial population. Default is weight.mutation.std.dev
#weight.mutation.std.dev.initial=0.01

#percent of individuals used as parents
survival.rate=0.4
#proportion of sexual (crossover) versus asexual reproduction.
crossover.proportion=0.5
# the probability that an individual produced by the crossover operator will be a candidate for having mutations applied to it (independent of other mutation probabilities).
crossover.mutate.probability=0

#[1, 5]
selector.elitism.min.specie.size=10
#percent of individuals from each species copied to next generation unchanged
selector.elitism.proportion=0.05
#min number to select from a species (if it has size >= selector.elitism.min.specie.size)
selector.elitism.min.to.select=1
selector.roulette=false
selector.min.generations=10
selector.max.stagnant.generations=250
selector.speciated.fitness=true


############
# speciation
############
speciation.class=com.anji.neat.SpeciationStrategyKMeans

#species distance factors
#c1, excess genes factor [1.0, 2.0]
chrom.compat.excess.coeff=2
#c2, disjoint genes factor [1.0, 2.0]
chrom.compat.disjoint.coeff=2
#c3, Weight difference factor [0.2, 3.0]
chrom.compat.common.coeff=1.0

#compatibility threshold [0.1, 4.0], relative to c#
#speciation.threshold=2.3
#speciation.target=32
#speciation.threshold.change=0.05


##################
# fitness function
##################
fitness_function.class=com.ojcoleman.ahni.experiments.MDP
#max threads to use for fitness evaluation (including transcription of genotype/cppn to phenotype/substrate)
#if value is <= 0 then the detected number of processor cores will be used
fitness.max_threads=1

#fitness.function.multi.class=com.ojcoleman.ahni.evaluation.mocostfunctions.BainNNConnectionCountCost
#fitness.function.multi.weighting=0.9999, 0.0001
#fitness.function.multi.probability=0

#experiment specific

# The task, either 'act' or 'predict'. Default is 'act'.
fitness.function.mdp.task=predict

#The number of environments to evaluate candidates against. Increasing this will provide a more accurate evaluation but take longer.
fitness.function.mdp.environment.count=1

# The fraction of environments that should be replaced with new environments per generation. This is evaluated
# probabilistically.
#fitness.function.mdp.environment.replacerate=0

# Factor to increase the total number of environments by when the current environment(s) have been 
# sufficiently mastered (see fitness.function.mdp.difficulty.increase.performance). May be fractional; if the factor is 
# greater than 1 then the number of environments will be increased by at least 1. Default is 1 (no change).
fitness.function.mdp.environment.count.increase=2

# If fitness.function.mdp.environment.count.increase is greater than 1, then this is the maximum number of 
# environments to increase to. Default is 128.
fitness.function.mdp.environment.count.max=128


# The number of trials per environment. If not set or set to <= 0 then this will be set to the grid size if
# fitness.function.mdp.grid is true and fitness.function.mdp.single_reward_state is true, otherwise to
# fitness.function.mdp.environment.count if fitness.function.mdp.environment.replacerate is 0, otherwise to
# fitness.function.mdp.states.maximum * fitness.function.mdp.actions.maximum
#fitness.function.mdp.trial.count=$(fitness.function.mdp.environment.count)
fitness.function.mdp.trial.count=1

# The number of steps in the environment per trial. If not set or set to <= 0 then this will be set depending on the number of trials. 
# If the number of trials is 1 then it will be set to (actionCount * stateCount * stateCount) / trialCount, 
# if the number of trials > 1 then it will be set to stateCount.
#fitness.function.mdp.trial.steps=4

#The initial number of states in the generated environments.
fitness.function.mdp.states.initial=3
#The maximum amount to increase the number of states in the generated environments to.
fitness.function.mdp.states.maximum=$(fitness.function.mdp.states.initial)
#The amount to increase the number of states in the generated environments when the current size has been sufficiently mastered.
#If the value is followed by an "x" then the value is considered a factor (and so should be > 1).
fitness.function.mdp.states.delta=0

#The initial number of actions available in the generated environments.
fitness.function.mdp.actions.initial=2
#The maximum amount to increase the available number of actions in the generated environments to.
fitness.function.mdp.actions.maximum=$(fitness.function.mdp.actions.initial)
#The amount to increase the available number of actions in the generated environments when the current size has been sufficiently mastered (see {@link #DIFFICULTY_INCREASE_PERFORMANCE}.
#the value is followed by an "x" then the value is considered a factor (and so should be > 1).
fitness.function.mdp.actions.delta=0

# For the 'act' task, the performance indicating when the environment size/difficulty should be increased as the 
# current size has been sufficiently mastered. Performance is calculated as a proportion of the maximum possible 
# fitness (which is the sum of reward received over all trials in all environments).
# For the 'predict' task the performance is the RMSE of the prediction (but with anything below 0.5 error for each 
# output considered as 0 error), thus a good "increase performance" value in this case is 0.
fitness.function.mdp.difficulty.increase.performance=0.0

#The proportion of actions that will map to some other state. This is evaluated probabilistically for all states and actions when generating an environment.
fitness.function.mdp.action.map.ratio=1

#The proportion of state transitions that will contain a reward value greater than 0.
fitness.function.mdp.transition.reward.ratio=0.5

# The randomness of state transitions. A value of 0 will make state transitions deterministic (purely determined by the action performed), a value of 1 will make transitions completely random (action performed will be ignored).
fitness.function.mdp.transition.randomness=0.0

# Whether to include the previously performed action in the input to the agent. Default is false.
fitness.function.mdp.input.include.previous.action=true

# Whether to include the previous state in the input to the agent. Default is false.
fitness.function.mdp.input.include.previous.state=true

# Whether to include an input that indicates whether the agent should be exploring to learn about the environment
# or exploiting the knowledge it's learnt. Default is false.
fitness.function.mdp.input.include.expl=false

# If true enables novelty search for which behaviours are defined by the current state for each step of each trial of each environment. Default is false.
fitness.function.mdp.noveltysearch=true
# If true then makes novelty search the only objective. The fitness value is still used to determine performance. 
# Default is false. If true then fitness.function.mdp.noveltysearch is also forced to true.
fitness.function.mdp.noveltysearch.only=false
# If set to an integer > 0 then this many environments will be used to characterise an agents behaviour for novelty search. Defaults to fitness.function.mdp.environment.count.
fitness.function.mdp.noveltysearch.envs.count=4

# Seed to use to generate and simulate environments. If not specified then system time will be used.
#fitness.function.mdp.environment.randomseed=123

# Whether to generate environments where the states are organised in a grid. The number of states is forced to
# (ceil(sqrt(state_count)))^2. The number of actions is forced to 4 and each action will move the agent to a
# neighbouring state. The input to the agent is the row and column index of the current state (1-of-N encoding for
# each). The environments are forced to be deterministic (no transition randomness). Default is false.
#fitness.function.mdp.grid=false

# Whether to make the grid toroidal (wrap around at edges). Default is false.
#fitness.function.mdp.grid.wrap=true

# Whether there should be a single state which when reached yields a reward value of 1 (rather than any transition
# to any state yielding a randomly generated reward value according to
# fitness.function.mdp.transition.reward.ratio. Default is false.
#fitness.function.mdp.single_reward_state=false


######## Novelty search (global parameters)

# The number of nearest neighbours to consider when determining the sparseness in a region and so whether to add a new individual to the archive. Default is 30.
fitness.function.novelty.k=15

# The novelty threshold to determine whether an individual is novel enough to add to the archive. The novelty
# of an individual is always in the range [0, 1], thus the threshold should also be within this range. Default
# is 0.05. An alternative method where individuals are added probabilistically can be used by removing this option
# and setting fitness.function.novelty.add_probability > 0. This option is mutually exclusive with 
# fitness.function.novelty.add_probability
#fitness.function.novelty.threshold=0.4

# The minimum value to decrease the novelty threshold to (the threshold is slowly reduced if no individuals are
# added in a generation). Default is 0.05 * fitness.function.novelty.threshold.
#fitness.function.novelty.threshold.min=0.0025

# The probability for each individual from the current generation that it will be added to the archive. For 
# example if the population size is 1000 and fitness.function.novelty.add_probability == 0.001, then on average
# one (randomly selected) individual will be added to the archive. This option is mutually exclusive with 
# fitness.function.novelty.threshold. Default is 0 (disabled, threshold method will be used instead).
fitness.function.novelty.add_probability=0.001


######## Generic novelty search fitness function (if included in fitness.function.multi.class)

# The number of sequences to test individuals on.
fitness.function.generic_novelty.sequence_count=8

# The number of output samples to record for each sequence.
fitness.function.generic_novelty.sample_count=4

# Output samples will be taken every [fitness.function.generic_novelty.sampling_interval]th step in the sequence. Default is 1 (take a sample every step).
fitness.function.generic_novelty.sampling_interval=4

# The minimum input value. Default is 0.
fitness.function.generic_novelty.input.min=-1

# The maximum input value. Default is 1.
fitness.function.generic_novelty.input.max=1


######## target connection count fitness function (if included in fitness.function.multi.class)

# The target proportion of synapses based on maximum possible number of synapses (calculated as number of neurons squared). Default is 0.
#fitness.function.connection_count_cost.target=0.2


################
# Network arch #
################

ann.transcriber.class=com.ojcoleman.ahni.transcriber.NEATTranscriberBain
ann.transcriber.neuron.model=com.ojcoleman.bain.neuron.rate.SigmoidNeuronCollection
ann.transcriber.synapse.model=com.ojcoleman.bain.synapse.rate.FixedSynapseCollection

recurrent=best_guess

#input and output size determined by fitness function settings
#stimulus.size=6
#response.size=6

#ann.transcriber.bain.maxrecurrentcyclesearchlength=20
ann.transcriber.bain.executionmode=SEQ

#ann.transcriber.connection.weight.min=-2
ann.transcriber.connection.weight.max=32

# These HyperNEAT params allow using the fitness function to specify the input and output sizes. 
ann.hyperneat.depth=2
# input and output layer dimensions determined by fitness function
ann.hyperneat.width=f,f
ann.hyperneat.height=f,f

#############
# persistence
#############
persistence.class=com.anji.persistence.FilePersistence
persistence.base.dir=./db
persist.enable=false
persist.all=false
persist.champions=false
persist.last=false
persist.load.genotype=false
id.file=./db/id.xml
neat.id.file=./db/neatid.xml

##############
# presentation
##############
presentation.generate=false
presentation.dir=./nevt

#########
# logging
#########
# How often to produce a line in the log containing a brief summary of the current progress.
log.pergenerations=1

# FileAppenders with the name RunLog receive special treatment: for each run the output will be directed to a file 
# with the name specified by log4j.appender.RunLog.File in the directory [output.dir]/[run number]/
#log4j.rootLogger=INFO, C, RunLog
log4j.rootLogger=INFO, C, RunLog
log4j.appender.C=org.apache.log4j.ConsoleAppender
log4j.appender.RunLog=org.apache.log4j.FileAppender
log4j.appender.RunLog.File=log.txt
log4j.appender.C.layout=org.apache.log4j.PatternLayout
log4j.appender.RunLog.layout=org.apache.log4j.PatternLayout
log4j.appender.C.layout.ConversionPattern=%-5p %m%x%n
log4j.appender.RunLog.layout.ConversionPattern=%-5p %m%x%n

################
# other output #
################
output.dir=/home/data/temp/ahni/$(run.name)
# Whether to log the champ to a text file and/or image. N < 0 indicates no logging, N=0 indicates 
# only at the end of evolution, N > 0 indicates every N generations and after evolution has finished.
log.champ.tostring=100
log.champ.toimage=100
log.champ.evaluation=100


#######################################
# parameter tuning via ParameterTuner #
#######################################

parametertuner.totune=       add.neuron.mutation.rate, add.neuron.anywhere.mutation.rate, add.connection.mutation.rate, weight.mutation.rate, weight.mutation.std.dev
parametertuner.initialvalues=0.001,                    0.001,                             0.0015,                       0.5,                  0.5
parametertuner.minvalues=    0,                        0,                                 0,                            0,                    0.01
parametertuner.maxvalues=    1,                        1,                                 1,                            1,                    100
parametertuner.initialvalueadjustfactor=2
parametertuner.numruns=100
parametertuner.numgens=500
parametertuner.solvedperformance=0.98
parametertuner.htcondor=\
  executable = ../ahni.jar \n \
  jar_files = ../ahni.jar
